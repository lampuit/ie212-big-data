{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------+---------------+--------------------+--------+-----------------+-------------------------+-----------+--------------------+-----------------+-----------------+\n",
      "|Item_Identifier|Item_Weight|Item_Fat_Content|Item_Visibility|           Item_Type|Item_MRP|Outlet_Identifier|Outlet_Establishment_Year|Outlet_Size|Outlet_Location_Type|      Outlet_Type|Item_Outlet_Sales|\n",
      "+---------------+-----------+----------------+---------------+--------------------+--------+-----------------+-------------------------+-----------+--------------------+-----------------+-----------------+\n",
      "|          FDA15|        9.3|         Low Fat|    0.016047301|               Dairy|249.8092|           OUT049|                     1999|     Medium|              Tier 1|Supermarket Type1|         3735.138|\n",
      "|          DRC01|       5.92|         Regular|    0.019278216|         Soft Drinks| 48.2692|           OUT018|                     2009|     Medium|              Tier 3|Supermarket Type2|         443.4228|\n",
      "|          FDN15|       17.5|         Low Fat|    0.016760075|                Meat| 141.618|           OUT049|                     1999|     Medium|              Tier 1|Supermarket Type1|          2097.27|\n",
      "|          FDX07|       19.2|         Regular|            0.0|Fruits and Vegeta...| 182.095|           OUT010|                     1998|       NULL|              Tier 3|    Grocery Store|           732.38|\n",
      "|          NCD19|       8.93|         Low Fat|            0.0|           Household| 53.8614|           OUT013|                     1987|       High|              Tier 3|Supermarket Type1|         994.7052|\n",
      "+---------------+-----------+----------------+---------------+--------------------+--------+-----------------+-------------------------+-----------+--------------------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Item_Identifier: string (nullable = true)\n",
      " |-- Item_Weight: double (nullable = true)\n",
      " |-- Item_Fat_Content: string (nullable = true)\n",
      " |-- Item_Visibility: double (nullable = true)\n",
      " |-- Item_Type: string (nullable = true)\n",
      " |-- Item_MRP: double (nullable = true)\n",
      " |-- Outlet_Identifier: string (nullable = true)\n",
      " |-- Outlet_Establishment_Year: integer (nullable = true)\n",
      " |-- Outlet_Size: string (nullable = true)\n",
      " |-- Outlet_Location_Type: string (nullable = true)\n",
      " |-- Outlet_Type: string (nullable = true)\n",
      " |-- Item_Outlet_Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TrainPredictionModel\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load training data\n",
    "train_path = \"Train.csv\"\n",
    "train_data = spark.read.csv(train_path, header=True, inferSchema=True)\n",
    "\n",
    "# Display first few rows of training data to understand its structure\n",
    "train_data.show(5)\n",
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+----------------+---------------+---------+--------+-----------------+-------------------------+-----------+--------------------+-----------+-----------------+\n",
      "|Item_Identifier|Item_Weight|Item_Fat_Content|Item_Visibility|Item_Type|Item_MRP|Outlet_Identifier|Outlet_Establishment_Year|Outlet_Size|Outlet_Location_Type|Outlet_Type|Item_Outlet_Sales|\n",
      "+---------------+-----------+----------------+---------------+---------+--------+-----------------+-------------------------+-----------+--------------------+-----------+-----------------+\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|       true|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|       true|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|       true|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|       true|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|       true|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "|          false|      false|           false|          false|    false|   false|            false|                    false|      false|               false|      false|            false|\n",
      "+---------------+-----------+----------------+---------------+---------+--------+-----------------+-------------------------+-----------+--------------------+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------+-----------+----------------+---------------+------------+--------+-----------------+-------------------------+-----------+--------------------+-----------------+-----------------+\n",
      "|Item_Identifier|Item_Weight|Item_Fat_Content|Item_Visibility|   Item_Type|Item_MRP|Outlet_Identifier|Outlet_Establishment_Year|Outlet_Size|Outlet_Location_Type|      Outlet_Type|Item_Outlet_Sales|\n",
      "+---------------+-----------+----------------+---------------+------------+--------+-----------------+-------------------------+-----------+--------------------+-----------------+-----------------+\n",
      "|          FDA15|        9.3|         Low Fat|    0.016047301|       Dairy|249.8092|           OUT049|                     1999|     Medium|              Tier 1|Supermarket Type1|         3735.138|\n",
      "|          DRC01|       5.92|         Regular|    0.019278216| Soft Drinks| 48.2692|           OUT018|                     2009|     Medium|              Tier 3|Supermarket Type2|         443.4228|\n",
      "|          FDN15|       17.5|         Low Fat|    0.016760075|        Meat| 141.618|           OUT049|                     1999|     Medium|              Tier 1|Supermarket Type1|          2097.27|\n",
      "|          NCD19|       8.93|         Low Fat|            0.0|   Household| 53.8614|           OUT013|                     1987|       High|              Tier 3|Supermarket Type1|         994.7052|\n",
      "|          FDP36|     10.395|         Regular|            0.0|Baking Goods| 51.4008|           OUT018|                     2009|     Medium|              Tier 3|Supermarket Type2|         556.6088|\n",
      "+---------------+-----------+----------------+---------------+------------+--------+-----------------+-------------------------+-----------+--------------------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in the dataset\n",
    "train_data.select([col(c).isNull().alias(c) for c in train_data.columns]).show()\n",
    "\n",
    "# Drop rows with null values (or fill them as needed)\n",
    "train_data = train_data.na.drop()\n",
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to string type\n",
    "categorical_columns = ['Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n",
    "\n",
    "for col_name in categorical_columns:\n",
    "    train_data = train_data.withColumn(col_name, train_data[col_name].cast('string'))\n",
    "    \n",
    "\n",
    "# Convert numerical columns to double type\n",
    "numerical_columns = ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year', 'Item_Outlet_Sales']\n",
    "for col_name in numerical_columns:\n",
    "    train_data = train_data.withColumn(col_name, train_data[col_name].cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply string indexer and one hot encoder to categorical columns\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid='skip') for col in categorical_columns]\n",
    "encoders = [OneHotEncoder(inputCol=col + \"_index\", outputCol=col + \"_encoded\") for col in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature vector for all columns\n",
    "feature_columns =  ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year', 'Item_Outlet_Sales']\\\n",
    "\n",
    "# [col + \"_encoded\" for col in categorical_columns] +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/14 01:15:34 WARN Instrumentation: [0838afcf] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training successful!\n",
      "Test Accuracy: 0.0\n",
      "F1-Score = 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "train_data = train_data.withColumn(\n",
    "    \"label\",\n",
    "    when(col(\"Item_Outlet_Sales\") < 500, 0)\n",
    "    .when((col(\"Item_Outlet_Sales\") >= 500) & (col(\"Item_Outlet_Sales\") < 1000), 1)\n",
    "    .otherwise(2)\n",
    ")\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Define Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "# Táº¡o pipeline\n",
    "assembler = VectorAssembler(inputCols=[\"Item_Weight\", \"Item_Visibility\", \"Item_MRP\", \"Outlet_Establishment_Year\"], outputCol=\"features\")\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Item_Outlet_Sales\")\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "# Split data into training and testing\n",
    "train_set, test_set = train_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    model = pipeline.fit(train_set)\n",
    "    print(\"Model training successful!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during model training: {e}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "try:\n",
    "    predictions = model.transform(test_set)\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    "    )\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(f\"Test Accuracy: {accuracy}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during model evaluation: {e}\")\n",
    "    \n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Item_Outlet_Sales\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    ")\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "print(f\"F1-Score = {f1_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.ml.pipeline.PipelineModel'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully to model\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "# import os\n",
    "# os.environ['JAVA_HOME'] = r'C:\\Program Files\\Java\\jdk-1.8'\n",
    "# os.environ['HADOOP_HOME'] = r'D:\\Spark\\spark-3.5.3-bin-hadoop3'\n",
    "\n",
    "model_path = 'model'\n",
    "\n",
    "try:\n",
    "    model.write().overwrite().save(model_path)\n",
    "    print(f\"Model saved successfully to {model_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.ml.feature import VectorAssembler\n",
    "# from pyspark.ml.regression import LinearRegression\n",
    "# from pyspark.ml import Pipeline\n",
    "\n",
    "# # Initialize Spark Session\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"TrainingModel\") \\\n",
    "#     .getOrCreate()\n",
    "\n",
    "# # Load Dataset\n",
    "# dataset_path = \"Train.csv\"  # Path to the dataset\n",
    "# df = spark.read.csv(dataset_path, header=True, inferSchema=True)\n",
    "\n",
    "# # Define Feature Columns and Label\n",
    "# feature_columns = [\"Item_Weight\", \"Item_Visibility\", \"Item_MRP\", \"Outlet_Establishment_Year\"]\n",
    "# assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# # Define Linear Regression Model\n",
    "# lr = LinearRegression(featuresCol=\"features\", labelCol=\"Item_Outlet_Sales\")\n",
    "\n",
    "# # Create Pipeline\n",
    "# pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "# # Train Model\n",
    "# model = pipeline.fit(df)\n",
    "\n",
    "# # Save Model\n",
    "# model_path = \"model\"\n",
    "# model.write().overwrite().save(model_path)\n",
    "\n",
    "# print(\"Model training completed and saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
