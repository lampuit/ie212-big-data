{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyspark consumer for streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/lamp/Projects/big-data/venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/lamp/.ivy2/cache\n",
      "The jars for the packages stored in: /home/lamp/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-6b7d74bd-9eb3-4a71-bd9d-c14d02b0143a;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.4 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.4 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      ":: resolution report :: resolve 205ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.4 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.4 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.5 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-6b7d74bd-9eb3-4a71-bd9d-c14d02b0143a\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 11 already retrieved (0kB/4ms)\n",
      "25/01/14 20:36:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import Normalizer, StandardScaler\n",
    "import random\n",
    "\n",
    "import time\n",
    "\n",
    "kafka_topic_name = \"songTopic\"\n",
    "kafka_bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "#spark version = 3.5.3\n",
    "#scala version = 2.12.18\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Spotify Streaming Reccomendation System\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.4\") \\\n",
    "        .getOrCreate()\\\n",
    "\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a streaming DataFrame that reads from test-topic\n",
    "songs_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "    .option(\"subscribe\", kafka_topic_name) \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df1 = songs_df.selectExpr(\"CAST(value AS STRING)\", \"timestamp\")\n",
    "\n",
    "\n",
    "songs_schema_string = \"order_id INT,id STRING, name STRING,popularity INT, duration_ms DOUBLE, explicit INT, \" \\\n",
    "                        + \"artists STRING, id_artists STRING, release_date STRING, \" \\\n",
    "                        + \"danceability DOUBLE,\" \\\n",
    "                        + \"energy DOUBLE, key INT, loudness DOUBLE, \" \\\n",
    "                        + \"mode INT,\" \\\n",
    "                        + \"speechiness DOUBLE,\" \\\n",
    "                        + \"acousticness DOUBLE, instrumentalness DOUBLE, liveness DOUBLE, \" \\\n",
    "                        + \"valence DOUBLE, tempo DOUBLE, time_signature DOUBLE\"\n",
    "\n",
    "\n",
    "\n",
    "songs_df2 = songs_df1 \\\n",
    "        .select(from_csv(col(\"value\"), songs_schema_string) \\\n",
    "                .alias(\"song\"), \"timestamp\")\n",
    "\n",
    "\n",
    "songs_df3 = songs_df2.select(\"song.*\", \"timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark SQL View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df3.createOrReplaceTempView(\"song_find\")\n",
    "song_find_text = spark.sql(\"SELECT * FROM song_find\")\n",
    "songs_agg_write_stream = song_find_text \\\n",
    "        .writeStream \\\n",
    "        .trigger(processingTime='5 seconds') \\\n",
    "        .outputMode(\"append\") \\\n",
    "        .option(\"truncate\", \"false\") \\\n",
    "        .format(\"memory\") \\\n",
    "        .queryName(\"testedTable5\") \\\n",
    "        .start()\n",
    "\n",
    "songs_agg_write_stream.awaitTermination(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spotipy --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Favorite song data generated using Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 20:36:41.903: Not loading module \"atk-bridge\": The functionality is provided by GTK natively. Please try to not load it.\n",
      "HTTP Error for GET to https://api.spotify.com/v1/audio-features/?ids=1N1ZpYUJc9fwrqk53FGgWv with Params: {} returned 403 due to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 tracks\n"
     ]
    },
    {
     "ename": "SpotifyException",
     "evalue": "http status: 403, code:-1 - https://api.spotify.com/v1/audio-features/?ids=1N1ZpYUJc9fwrqk53FGgWv:\n None, reason: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/big-data/venv/lib/python3.12/site-packages/spotipy/client.py:275\u001b[0m, in \u001b[0;36mSpotify._internal_call\u001b[0;34m(self, method, url, payload, params)\u001b[0m\n\u001b[1;32m    270\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    271\u001b[0m     method, url, headers\u001b[38;5;241m=\u001b[39mheaders, proxies\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[1;32m    272\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequests_timeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs\n\u001b[1;32m    273\u001b[0m )\n\u001b[0;32m--> 275\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m results \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/Projects/big-data/venv/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://api.spotify.com/v1/audio-features/?ids=1N1ZpYUJc9fwrqk53FGgWv",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSpotifyException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspotify_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getSong\n\u001b[1;32m      3\u001b[0m song_data \u001b[38;5;241m=\u001b[39m getSong\u001b[38;5;241m.\u001b[39mpasss()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#song_data.rename(columns={'duration_s': 'duration_ms' }, inplace=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/big-data/kafka/tutorial12/spotify_api.py:65\u001b[0m\n\u001b[1;32m     62\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idd \u001b[38;5;129;01min\u001b[39;00m tracks_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist():\n\u001b[0;32m---> 65\u001b[0m     audio_features[idd] \u001b[38;5;241m=\u001b[39m \u001b[43mspotipy_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43midd\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     67\u001b[0m tracks_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macousticness\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tracks_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m idd: audio_features[idd][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macousticness\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     68\u001b[0m tracks_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeechiness\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tracks_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m idd: audio_features[idd][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeechiness\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Projects/big-data/venv/lib/python3.12/site-packages/spotipy/client.py:1799\u001b[0m, in \u001b[0;36mSpotify.audio_features\u001b[0;34m(self, tracks)\u001b[0m\n\u001b[1;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tracks, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1798\u001b[0m     trackid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m, tracks)\n\u001b[0;32m-> 1799\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio-features/?ids=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrackid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1801\u001b[0m     tlist \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m, t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tracks]\n",
      "File \u001b[0;32m~/Projects/big-data/venv/lib/python3.12/site-packages/spotipy/client.py:327\u001b[0m, in \u001b[0;36mSpotify._get\u001b[0;34m(self, url, args, payload, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[1;32m    325\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(args)\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/big-data/venv/lib/python3.12/site-packages/spotipy/client.py:297\u001b[0m, in \u001b[0;36mSpotify._internal_call\u001b[0;34m(self, method, url, payload, params)\u001b[0m\n\u001b[1;32m    290\u001b[0m         reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Error for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with Params: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m returned \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m due to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    294\u001b[0m         method, url, args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m), response\u001b[38;5;241m.\u001b[39mstatus_code, msg\n\u001b[1;32m    295\u001b[0m     )\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SpotifyException(\n\u001b[1;32m    298\u001b[0m         response\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    301\u001b[0m         reason\u001b[38;5;241m=\u001b[39mreason,\n\u001b[1;32m    302\u001b[0m         headers\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRetryError \u001b[38;5;28;01mas\u001b[39;00m retry_error:\n\u001b[1;32m    305\u001b[0m     request \u001b[38;5;241m=\u001b[39m retry_error\u001b[38;5;241m.\u001b[39mrequest\n",
      "\u001b[0;31mSpotifyException\u001b[0m: http status: 403, code:-1 - https://api.spotify.com/v1/audio-features/?ids=1N1ZpYUJc9fwrqk53FGgWv:\n None, reason: None"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from spotify_api import getSong\n",
    "\n",
    "song_data = getSong.passs()\n",
    "#song_data.rename(columns={'duration_s': 'duration_ms' }, inplace=True)\n",
    "song_data = song_data.drop(['id', 'added_at', 'time_signature','duration_s'], axis='columns')\n",
    "rand_n = random.randint(0, len(song_data) - 1)\n",
    "add_df = song_data.head(rand_n)[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m      5\u001b[0m df_stream \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexplicit\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration_ms\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m df_sp \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(\u001b[43madd_df\u001b[49m)\n\u001b[1;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39munion(df_sp)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VectorAssembler\n",
      "\u001b[0;31mNameError\u001b[0m: name 'add_df' is not defined"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT * FROM testedTable5\")\n",
    "\n",
    "df = df.sort(df.release_date.desc())\n",
    "\n",
    "df_stream = df\n",
    "\n",
    "df = df.drop('order_id',\n",
    "'id',\n",
    "'explicit',\n",
    "'mode',\n",
    "'release_date',\n",
    "'id_artists',\n",
    "'time_signature',\n",
    "'duration_ms',\n",
    "'timestamp')\n",
    "\n",
    "df_sp = spark.createDataFrame(add_df)\n",
    "df = df.union(df_sp)\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler=VectorAssembler(inputCols=[\n",
    "'danceability',\n",
    "'energy',\n",
    "'loudness',\n",
    "'speechiness',\n",
    "'acousticness',\n",
    "'instrumentalness',\n",
    "'liveness',\n",
    "'valence',\n",
    "'tempo'], outputCol='features')\n",
    "assembled_data=assembler.setHandleInvalid(\"skip\").transform(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
